{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# todo reset parameters for linear layer\n",
    "class DynamicModel(nn.Module):\n",
    "    def __init__(self, max_length, batch_size):\n",
    "        super(DynamicModel, self).__init__()\n",
    "        weights_matrix = data_loader.weight_matrix\n",
    "        self.max_length = max_length\n",
    "        self.batch_size = batch_size\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.tensor(weights_matrix), freeze=False)\n",
    "        self.dcnn_first_cell = DCNNCell(\n",
    "            cell_number=-1,\n",
    "            sent_length=self.parameter_dict[\"cell_one_parameter_dict\"][\"sent_length\"],\n",
    "            conv_kernel_size=self.parameter_dict[\"cell_one_parameter_dict\"][\"conv_kernel_size\"],\n",
    "            conv_input_channels=self.parameter_dict[\"cell_one_parameter_dict\"][\"conv_input_channels\"],\n",
    "            conv_output_channels=self.parameter_dict[\"cell_one_parameter_dict\"][\"conv_output_channels\"],\n",
    "            conv_stride=self.parameter_dict[\"cell_one_parameter_dict\"][\"conv_stride\"],\n",
    "            k_max_number=self.parameter_dict[\"cell_one_parameter_dict\"][\"k_max_number\"],\n",
    "            folding_kernel_size=self.parameter_dict[\"cell_one_parameter_dict\"][\"folding_kernel_size\"],\n",
    "            folding_stride=self.parameter_dict[\"cell_one_parameter_dict\"][\"folding_stride\"],\n",
    "        )\n",
    "        self.dcnn_last_cell = DCNNCell(\n",
    "            cell_number=-1,\n",
    "            sent_length=self.parameter_dict[\"cell_two_parameter_dict\"][\"sent_length\"],\n",
    "            conv_kernel_size=self.parameter_dict[\"cell_two_parameter_dict\"][\"conv_kernel_size\"],\n",
    "            conv_input_channels=self.parameter_dict[\"cell_two_parameter_dict\"][\"conv_input_channels\"],\n",
    "            conv_output_channels=self.parameter_dict[\"cell_two_parameter_dict\"][\"conv_output_channels\"],\n",
    "            conv_stride=self.parameter_dict[\"cell_two_parameter_dict\"][\"conv_stride\"],\n",
    "            k_max_number=self.parameter_dict[\"cell_two_parameter_dict\"][\"k_max_number\"],\n",
    "            folding_kernel_size=self.parameter_dict[\"cell_two_parameter_dict\"][\"folding_kernel_size\"],\n",
    "            folding_stride=self.parameter_dict[\"cell_two_parameter_dict\"][\"folding_stride\"],\n",
    "        )        \n",
    "        self.fc_layer_input = self.parameter_dict[\"cell_two_parameter_dict\"][\"k_max_number\"] *\\\n",
    "            self.parameter_dict[\"cell_two_parameter_dict\"][\"conv_output_channels\"] *\\\n",
    "            math.floor(self.parameter_dict[\"embedding_dim\"]/4)\n",
    "            \n",
    "        self.dropout = nn.Dropout(self.parameter_dict[\"dropout_rate\"])\n",
    "        self.flatten = Flatten()\n",
    "        self.fc = nn.Linear(self.fc_layer_input, self.parameter_dict[\"output_dim\"])\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        # [batch_size, sent_length]\n",
    "        embedded = self.embedding(inp)\n",
    "        # [batch_size, sent_length, embedding_dim]\n",
    "        # adding single channel dimension\n",
    "        embedded = embedded.unsqueeze(1)\n",
    "        # print(embedded.shape)\n",
    "        # [batch_size, 1(initial_input_channel), sent_length, embedding_dim]\n",
    "        out = self.dcnn_first_cell(embedded)\n",
    "        # print(out.shape)\n",
    "        # [batch_size, first_cell_output_channels, first_cell_k_maxed_number, embedding_dim]\n",
    "        out = self.dcnn_last_cell(out)\n",
    "        # print(out.shape)\n",
    "        # [batch_size, last_cell_output_channels, last_cell_k_maxed_number, embedding_dim/2]\n",
    "        out = self.dropout(self.flatten(out))\n",
    "        # print(flat.shape)\n",
    "        #[batch_size, last_cell_output_channels * last_cell_k_maxed_number * embedding_dim/2]\n",
    "        out = self.fc(out)\n",
    "        # print(fc.shape)\n",
    "        return out\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ReviewModelParam = {\n",
    "    \"max_length\": 60,\n",
    "    \"emdedding_dim\": 50,\n",
    "    \"vocab_length\" : data_loader.weight_matrix.shape[0],\n",
    "    \"output_dim\" : 2,\n",
    "    \"batch_size\" : 128,\n",
    "    \n",
    "    \"first_dropout\" : 0.5,\n",
    "    \"conv_input_channel\": None,\n",
    "    \"conv_output_channel\" : 200,\n",
    "    \"conv_padding\" : 2,\n",
    "    \"conv1_kernel_size\" : 4,\n",
    "    \"conv2_kernel_size\" : 5,\n",
    "    \"maxpool_kernel_size\" : 2,\n",
    "    \"second_dropout\" : 0.3,\n",
    "    \"rnn_input_size\": None,\n",
    "    \"rnn_hidden_size\" : 100,\n",
    "    \"rnn_num_layers\" : 1,\n",
    "    \"first_dense_in\":None,\n",
    "    \"first_dense_out\" : 400\n",
    "    \"third_dropout\": 0.15,\n",
    "    \"second_dense_in\" : None,\n",
    "    \"second_dense_out\" : None\n",
    "    }\n",
    "ReviewModelParam[\"conv1_input_channel\"] = ReviewModelParam[\"embedding_dim\"]\n",
    "ReviewModelParam[\"rnn_input_size\"] = ReviewModelParam[\"conv_output_channel\"]*2\n",
    "ReviewModelParam[\"first_dense_in\"] = ReviewModelParam[\"max_length\"]//2 * ReviewModelParam[\"rnn_hidden_size\"]\n",
    "ReviewModelParam[\"second_dense_in\"] = ReviewModelParam[\"first_dense_out\"]\n",
    "ReviewModelParam[\"second_dense_out\"] = ReviewModelParam[\"output_dim\"]  ##depends on loss function\n",
    "\n",
    "SST1_DATASET_PARAMETERS[\"cell_two_parameter_dict\"][\"sent_length\"] = SST1_DATASET_PARAMETERS[\"cell_one_parameter_dict\"][\"k_max_number\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (<ipython-input-15-54be7ebdd964>, line 60)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-54be7ebdd964>\"\u001b[0;36m, line \u001b[0;32m60\u001b[0m\n\u001b[0;31m    return x\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "class DCNNCell(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        cell_number=1,\n",
    "        sent_length=7,\n",
    "        conv_kernel_size=(3, 1),\n",
    "        conv_input_channels=1,\n",
    "        conv_output_channels=2,\n",
    "        conv_stride=(1, 1),\n",
    "        k_max_number=5,\n",
    "        folding_kernel_size=(1, 2),\n",
    "        folding_stride=(1,1)\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.cell_number=cell_number \n",
    "        self.sent_length=sent_length\n",
    "        self.conv_kernel_size=conv_kernel_size\n",
    "        self.conv_input_channels=conv_input_channels\n",
    "        self.conv_output_channels=conv_output_channels\n",
    "        self.conv_stride=conv_stride\n",
    "        self.k_max_number=k_max_number\n",
    "        self.folding_kernel_size=folding_kernel_size\n",
    "        self.folding_stride=folding_stride\n",
    "        \n",
    "        # calculating padding size\n",
    "        self.pad_0_direction = math.ceil(self.conv_kernel_size[0]  - 1)\n",
    "        self.pad_1_direction = math.ceil(self.conv_kernel_size[1] - 1)\n",
    "        \n",
    "        # 2d convolution\n",
    "        self.conv_layer = nn.Conv2d(\n",
    "            in_channels=self.conv_input_channels,\n",
    "            out_channels=self.conv_output_channels,\n",
    "            kernel_size=self.conv_kernel_size,\n",
    "            stride=self.conv_stride,\n",
    "            padding=(self.pad_0_direction, self.pad_1_direction)\n",
    "        )\n",
    "        \n",
    "        # if cell is last then initialising folding\n",
    "        if cell_number == -1:\n",
    "            self.fold = nn.AvgPool2d(kernel_size=self.folding_kernel_size, stride=self.folding_stride)\n",
    "            \n",
    "    def forward(self, inp):\n",
    "        \n",
    "        # [batch_size, input_channels, sent_length_in, embedding_dim]\n",
    "        conved = self.conv_layer(inp)\n",
    "        \n",
    "        # [batch_size, out_channels, sent_length_out, embedding_dim]\n",
    "        if self.cell_number == -1:\n",
    "            conved = self.fold(conved)\n",
    "        \n",
    "        # [batch_size, out_channels, sent_length, embedding_dim/2]\n",
    "        k_maxed = torch.tanh(torch.topk(conved, self.k_max_number, dim=2, largest=True)[0])\n",
    "        \n",
    "        # [batch_size, out_channels, k_maxed_number, embedding_dim/2]\n",
    "        return k_maxed\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size()[0], -1)\n",
    "return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-14-064b680676e3>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-14-064b680676e3>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    from notebook2-Copy1 import AmznDataLoader\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from notebook2-Copy1 import AmznDataLoader"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
