{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from DynamicModel import *\n",
    "from ReviewModel import ReviewModel\n",
    "from dataLoader import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([29700, 60])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "iteration over a 0-d tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-f9554dd430a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m29700\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torchsummary/torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# batch_size of 2 for batchnorm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0min_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0min_size\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0;31m# print(type(x[0]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torchsummary/torchsummary.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# batch_size of 2 for batchnorm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0min_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0min_size\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0;31m# print(type(x[0]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work/modules/Ubuntu/14.04/amd64/common/anaconda3/latest/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;31m# map will interleave them.)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'iteration over a 0-d tensor'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m             warnings.warn('Iterating over a tensor might cause the trace to be incorrect. '\n",
      "\u001b[0;31mTypeError\u001b[0m: iteration over a 0-d tensor"
     ]
    }
   ],
   "source": [
    "summary(model,torch.LongTensor([1,29700, 60]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_losses(tr_loss, val_loss):\n",
    "    plt.plot(tr_loss, label=\"training\")\n",
    "    plt.plot(val_loss, label=\"validation\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9776\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAFlJJREFUeJzt3X+s3Xd93/HnCzsJKZTaIQ7zbGs21NowSDjBS8yYJhY6x0krHCSQHFWNxzK5Y4kEW7fhFKkpPyKRbYUqEoSmi4tTUUwWYLFSM88KqSokSHIDwYkJqS9JSi5xk8ucBBhaaNL3/jifCwd/z/W9vtf3npP5+ZC+Ot/v+/v5fs/7fO3j1z3f7/dcp6qQJKnfy4bdgCRp9BgOkqQOw0GS1GE4SJI6DAdJUofhIEnqMBwkSR2GgySpw3CQJHUsHXYDc3XuuefW2rVrh92GJL2k3H///T+oqhUzjXvJhsPatWsZGxsbdhuS9JKS5K9nM87TSpKkDsNBktRhOEiSOgwHSVKH4SBJ6jAcJEkdM4ZDkpcnuTfJt5IcTvKhVv9MkseSPNCmja2eJDcmGU9yKMkFffvakeRIm3b01d+c5MG2zY1JshAvVpI0O7P5nsPzwMVV9eMkZwBfTfLltu4/VtXtx42/FFjfpouAm4CLkpwDXAdsAgq4P8m+qnqmjdkJfB3YD2wFvowkaShm/ORQPT9ui2e06UT/8fQ24Na23deBZUlWApcAB6vqWAuEg8DWtu5VVfW16v2H1rcCl8/jNUmS5mlW35BOsgS4H/hV4JNVdU+S9wLXJ/k94C5gV1U9D6wCnujbfKLVTlSfGFBfMGt3/flC7n5aj3/s14fyvJJ0smZ1QbqqXqyqjcBq4MIkbwSuBf4R8I+Bc4APtOGDrhfUHOodSXYmGUsyNjk5OZvWJUlzcFJ3K1XVs8BfAFur6mg7dfQ88CfAhW3YBLCmb7PVwJMz1FcPqA96/puralNVbVqxYsbfGyVJmqPZ3K20IsmyNn828GvAd9q1AtqdRZcDD7VN9gFXtruWNgPPVdVR4ACwJcnyJMuBLcCBtu5HSTa3fV0J3HFqX6Yk6WTM5prDSmBPu+7wMuC2qrozyVeSrKB3WugB4N+08fuBy4Bx4CfAewCq6liSjwD3tXEfrqpjbf69wGeAs+ndpeSdSpI0RDOGQ1UdAs4fUL94mvEFXD3Nut3A7gH1MeCNM/UiSVocfkNaktRhOEiSOgwHSVKH4SBJ6jAcJEkdhoMkqcNwkCR1GA6SpA7DQZLUYThIkjoMB0lSh+EgSeowHCRJHYaDJKnDcJAkdRgOkqQOw0GS1GE4SJI6DAdJUofhIEnqMBwkSR0zhkOSlye5N8m3khxO8qFWX5fkniRHknw+yZmtflZbHm/r1/bt69pWfyTJJX31ra02nmTXqX+ZkqSTMZtPDs8DF1fVm4CNwNYkm4EbgE9U1XrgGeCqNv4q4Jmq+lXgE20cSTYA24E3AFuBTyVZkmQJ8EngUmADcEUbK0kakhnDoXp+3BbPaFMBFwO3t/oe4PI2v60t09a/PUlafW9VPV9VjwHjwIVtGq+qR6vqp8DeNlaSNCSzuubQfsJ/AHgaOAh8F3i2ql5oQyaAVW1+FfAEQFv/HPDq/vpx20xXH9THziRjScYmJydn07okaQ5mFQ5V9WJVbQRW0/tJ//WDhrXHTLPuZOuD+ri5qjZV1aYVK1bM3LgkaU5O6m6lqnoW+AtgM7AsydK2ajXwZJufANYAtPW/Ahzrrx+3zXR1SdKQzOZupRVJlrX5s4FfAx4G7gbe1YbtAO5o8/vaMm39V6qqWn17u5tpHbAeuBe4D1jf7n46k95F632n4sVJkuZm6cxDWAnsaXcVvQy4raruTPJtYG+SjwLfBG5p428B/jTJOL1PDNsBqupwktuAbwMvAFdX1YsASa4BDgBLgN1VdfiUvUJJ0kmbMRyq6hBw/oD6o/SuPxxf/7/Au6fZ1/XA9QPq+4H9s+hXkrQI/Ia0JKnDcJAkdRgOkqQOw0GS1GE4SJI6DAdJUofhIEnqMBwkSR2GgySpw3CQJHUYDpKkDsNBktRhOEiSOgwHSVKH4SBJ6jAcJEkdhoMkqcNwkCR1GA6SpA7DQZLUMWM4JFmT5O4kDyc5nOR9rf77Sb6f5IE2Xda3zbVJxpM8kuSSvvrWVhtPsquvvi7JPUmOJPl8kjNP9QuVJM3ebD45vAD8TlW9HtgMXJ1kQ1v3iara2Kb9AG3dduANwFbgU0mWJFkCfBK4FNgAXNG3nxvavtYDzwBXnaLXJ0magxnDoaqOVtU32vyPgIeBVSfYZBuwt6qer6rHgHHgwjaNV9WjVfVTYC+wLUmAi4Hb2/Z7gMvn+oIkSfN3UtcckqwFzgfuaaVrkhxKsjvJ8lZbBTzRt9lEq01XfzXwbFW9cFxdkjQksw6HJK8EvgC8v6p+CNwEvA7YCBwF/mBq6IDNaw71QT3sTDKWZGxycnK2rUuSTtKswiHJGfSC4bNV9UWAqnqqql6sqr8D/pjeaSPo/eS/pm/z1cCTJ6j/AFiWZOlx9Y6qurmqNlXVphUrVsymdUnSHMzmbqUAtwAPV9XH++or+4a9E3ioze8Dtic5K8k6YD1wL3AfsL7dmXQmvYvW+6qqgLuBd7XtdwB3zO9lSZLmY+nMQ3gr8FvAg0keaLXfpXe30UZ6p4AeB34boKoOJ7kN+Da9O52urqoXAZJcAxwAlgC7q+pw298HgL1JPgp8k14YSZKGZMZwqKqvMvi6wP4TbHM9cP2A+v5B21XVo/z8tJQkacj8hrQkqcNwkCR1GA6SpA7DQZLUYThIkjoMB0lSh+EgSeowHCRJHYaDJKnDcJAkdRgOkqQOw0GS1GE4SJI6DAdJUofhIEnqMBwkSR2GgySpw3CQJHUYDpKkDsNBktQxYzgkWZPk7iQPJzmc5H2tfk6Sg0mOtMflrZ4kNyYZT3IoyQV9+9rRxh9JsqOv/uYkD7ZtbkyShXixkqTZmc0nhxeA36mq1wObgauTbAB2AXdV1XrgrrYMcCmwvk07gZugFybAdcBFwIXAdVOB0sbs7Ntu6/xfmiRprmYMh6o6WlXfaPM/Ah4GVgHbgD1t2B7g8ja/Dbi1er4OLEuyErgEOFhVx6rqGeAgsLWte1VVfa2qCri1b1+SpCE4qWsOSdYC5wP3AK+pqqPQCxDgvDZsFfBE32YTrXai+sSAuiRpSGYdDkleCXwBeH9V/fBEQwfUag71QT3sTDKWZGxycnKmliVJczSrcEhyBr1g+GxVfbGVn2qnhGiPT7f6BLCmb/PVwJMz1FcPqHdU1c1VtamqNq1YsWI2rUuS5mA2dysFuAV4uKo+3rdqHzB1x9EO4I6++pXtrqXNwHPttNMBYEuS5e1C9BbgQFv3oySb23Nd2bcvSdIQLJ3FmLcCvwU8mOSBVvtd4GPAbUmuAr4HvLut2w9cBowDPwHeA1BVx5J8BLivjftwVR1r8+8FPgOcDXy5TZKkIZkxHKrqqwy+LgDw9gHjC7h6mn3tBnYPqI8Bb5ypF0nS4vAb0pKkDsNBktRhOEiSOgwHSVKH4SBJ6jAcJEkdhoMkqcNwkCR1GA6SpA7DQZLUYThIkjoMB0lSh+EgSeowHCRJHYaDJKnDcJAkdRgOkqQOw0GS1GE4SJI6DAdJUofhIEnqmDEckuxO8nSSh/pqv5/k+0keaNNlfeuuTTKe5JEkl/TVt7baeJJdffV1Se5JciTJ55OceSpfoCTp5M3mk8NngK0D6p+oqo1t2g+QZAOwHXhD2+ZTSZYkWQJ8ErgU2ABc0cYC3ND2tR54BrhqPi9IkjR/M4ZDVf0lcGyW+9sG7K2q56vqMWAcuLBN41X1aFX9FNgLbEsS4GLg9rb9HuDyk3wNkqRTbD7XHK5JcqiddlreaquAJ/rGTLTadPVXA89W1QvH1QdKsjPJWJKxycnJebQuSTqRuYbDTcDrgI3AUeAPWj0DxtYc6gNV1c1VtamqNq1YseLkOpYkzdrSuWxUVU9NzSf5Y+DOtjgBrOkbuhp4ss0Pqv8AWJZkafv00D9ekjQkc/rkkGRl3+I7gak7mfYB25OclWQdsB64F7gPWN/uTDqT3kXrfVVVwN3Au9r2O4A75tKTJOnUmfGTQ5LPAW8Dzk0yAVwHvC3JRnqngB4Hfhugqg4nuQ34NvACcHVVvdj2cw1wAFgC7K6qw+0pPgDsTfJR4JvALafs1UmS5mTGcKiqKwaUp/0HvKquB64fUN8P7B9Qf5Te3UySpBHhN6QlSR2GgySpw3CQJHUYDpKkDsNBktRhOEiSOgwHSVKH4SBJ6jAcJEkdhoMkqcNwkCR1GA6SpA7DQZLUYThIkjoMB0lSh+EgSeowHCRJHYaDJKnDcJAkdRgOkqSOGcMhye4kTyd5qK92TpKDSY60x+WtniQ3JhlPcijJBX3b7GjjjyTZ0Vd/c5IH2zY3JsmpfpGSpJMzm08OnwG2HlfbBdxVVeuBu9oywKXA+jbtBG6CXpgA1wEXARcC100FShuzs2+7459LkrTIZgyHqvpL4Nhx5W3Anja/B7i8r35r9XwdWJZkJXAJcLCqjlXVM8BBYGtb96qq+lpVFXBr374kSUMy12sOr6mqowDt8bxWXwU80TduotVOVJ8YUJckDdGpviA96HpBzaE+eOfJziRjScYmJyfn2KIkaSZzDYen2ikh2uPTrT4BrOkbtxp4cob66gH1garq5qraVFWbVqxYMcfWJUkzmWs47AOm7jjaAdzRV7+y3bW0GXiunXY6AGxJsrxdiN4CHGjrfpRkc7tL6cq+fUmShmTpTAOSfA54G3Bukgl6dx19DLgtyVXA94B3t+H7gcuAceAnwHsAqupYko8A97VxH66qqYvc76V3R9TZwJfbJEkaohnDoaqumGbV2weMLeDqafazG9g9oD4GvHGmPiRJi8dvSEuSOgwHSVKH4SBJ6jAcJEkdhoMkqcNwkCR1GA6SpA7DQZLUYThIkjoMB0lSh+EgSeowHCRJHYaDJKnDcJAkdRgOkqQOw0GS1GE4SJI6DAdJUofhIEnqMBwkSR2GgySpY17hkOTxJA8meSDJWKudk+RgkiPtcXmrJ8mNScaTHEpyQd9+drTxR5LsmN9LkiTN16n45PDPq2pjVW1qy7uAu6pqPXBXWwa4FFjfpp3ATdALE+A64CLgQuC6qUCRJA3HQpxW2gbsafN7gMv76rdWz9eBZUlWApcAB6vqWFU9AxwEti5AX5KkWZpvOBTwv5Lcn2Rnq72mqo4CtMfzWn0V8ETfthOtNl29I8nOJGNJxiYnJ+fZuiRpOkvnuf1bq+rJJOcBB5N85wRjM6BWJ6h3i1U3AzcDbNq0aeAYSdL8zeuTQ1U92R6fBr5E75rBU+10Ee3x6TZ8AljTt/lq4MkT1CVJQzLncEjyiiS/PDUPbAEeAvYBU3cc7QDuaPP7gCvbXUubgefaaacDwJYky9uF6C2tJkkakvmcVnoN8KUkU/v5s6r6n0nuA25LchXwPeDdbfx+4DJgHPgJ8B6AqjqW5CPAfW3ch6vq2Dz6kiTN05zDoaoeBd40oP6/gbcPqBdw9TT72g3snmsvkqRTy29IS5I6DAdJUofhIEnqMBwkSR2GgySpw3CQJHUYDpKkDsNBktRhOEiSOgwHSVKH4SBJ6jAcJEkdhoMkqcNwkCR1GA6SpI75/h/SOglrd/350J778Y/9+tCeW9JLj58cJEkdhoMkqcNwkCR1GA6SpI6RCYckW5M8kmQ8ya5h9yNJp7ORCIckS4BPApcCG4ArkmwYbleSdPoalVtZLwTGq+pRgCR7gW3At4fa1f9HhnUbrbfQSi9NoxIOq4An+pYngIuG1ItOIb/bIb00jUo4ZECtOoOSncDOtvjjJI/M8fnOBX4wx20Xw6j3By+BHnPDyPc46v3B6Pc46v3B6PX4D2YzaFTCYQJY07e8Gnjy+EFVdTNw83yfLMlYVW2a734Wyqj3B/Z4Kox6fzD6PY56f/DS6HGQkbggDdwHrE+yLsmZwHZg35B7kqTT1kh8cqiqF5JcAxwAlgC7q+rwkNuSpNPWSIQDQFXtB/Yv0tPN+9TUAhv1/sAeT4VR7w9Gv8dR7w9eGj12pKpz3VeSdJoblWsOkqQRclqFw6j8io4ka5LcneThJIeTvK/Vz0lyMMmR9ri81ZPkxtb3oSQXLFKfS5J8M8mdbXldkntaf59vNw+Q5Ky2PN7Wr12k/pYluT3Jd9qxfMsoHcMk/679+T6U5HNJXj7sY5hkd5KnkzzUVzvpY5ZkRxt/JMmORejxv7Q/50NJvpRkWd+6a1uPjyS5pK++IO/3Qf31rfsPSSrJuW15KMfwlKiq02Kid6H7u8BrgTOBbwEbhtTLSuCCNv/LwF/R+7Uh/xnY1eq7gBva/GXAl+l9H2QzcM8i9fnvgT8D7mzLtwHb2/yngfe2+X8LfLrNbwc+v0j97QH+dZs/E1g2KseQ3hc7HwPO7jt2/3LYxxD4Z8AFwEN9tZM6ZsA5wKPtcXmbX77APW4Blrb5G/p63NDey2cB69p7fMlCvt8H9dfqa+jdVPPXwLnDPIan5HUOu4FFe6HwFuBA3/K1wLXD7qv1cgfwL4BHgJWtthJ4pM3/EXBF3/ifjVvAnlYDdwEXA3e2v9w/6HuD/ux4tjfEW9r80jYuC9zfq9o/vjmuPhLHkJ9/6/+cdkzuBC4ZhWMIrD3uH96TOmbAFcAf9dV/YdxC9HjcuncCn23zv/A+njqOC/1+H9QfcDvwJuBxfh4OQzuG851Op9NKg35Fx6oh9fIz7fTB+cA9wGuq6ihAezyvDRtG738I/Cfg79ryq4Fnq+qFAT38rL+2/rk2fiG9FpgE/qSd+vpvSV7BiBzDqvo+8F+B7wFH6R2T+xmtYzjlZI/ZsN9L/4reT+OcoJdF7THJO4DvV9W3jls1Ev3NxekUDrP6FR2LKckrgS8A76+qH55o6IDagvWe5DeAp6vq/ln2MIxju5TeR/ubqup84P/QOyUyncU+hsvp/fLIdcDfB15B77cOT9fDyP39ZPqehtZrkg8CLwCfnSpN08ui9Zjkl4APAr83aPU0fYzin/cvOJ3CYVa/omOxJDmDXjB8tqq+2MpPJVnZ1q8Enm71xe79rcA7kjwO7KV3aukPgWVJpr4b09/Dz/pr638FOLaA/U0950RV3dOWb6cXFqNyDH8NeKyqJqvqb4EvAv+E0TqGU072mA3lvdQu2v4G8JvVzsWMSI+vo/dDwLfae2Y18I0kf29E+puT0ykcRuZXdCQJcAvwcFV9vG/VPmDqroUd9K5FTNWvbHc+bAaemzoNsBCq6tqqWl1Va+kdp69U1W8CdwPvmqa/qb7f1cYv6E9BVfU3wBNJ/mErvZ3er3gfiWNI73TS5iS/1P68p/obmWPY52SP2QFgS5Ll7RPSllZbMEm2Ah8A3lFVPzmu9+3tbq91wHrgXhbx/V5VD1bVeVW1tr1nJujdcPI3jNAxPGnDvuixmBO9Owf+it5dDB8cYh//lN5HyEPAA226jN455ruAI+3xnDY+9P4zpO8CDwKbFrHXt/Hzu5VeS++NNw78d+CsVn95Wx5v61+7SL1tBMbacfwf9O76GJljCHwI+A7wEPCn9O6oGeoxBD5H7xrI39L7R+yquRwzeuf9x9v0nkXocZzeOfqp98un+8Z/sPX4CHBpX31B3u+D+jtu/eP8/IL0UI7hqZj8hrQkqeN0Oq0kSZolw0GS1GE4SJI6DAdJUofhIEnqMBwkSR2GgySpw3CQJHX8P2/9I/QkHm3DAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_loader = AmznDataLoader( path ='./data/reviews_Amazon_Instant_Video_5.json.gz', maxSeqLength = 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ReviewModelParam = {\n",
    "    \"max_length\": 60,\n",
    "    \"embedding_dim\": 50,\n",
    "    \"vocab_length\" : data_loader.weight_matrix.shape[0],\n",
    "    \"output_dim\" : 5,\n",
    "    \"batch_size\" : 128,\n",
    "    \n",
    "    \"first_dropout\" : 0.5,\n",
    "    \"conv_input_channel\": None,\n",
    "    \"conv_output_channel\" : 200,\n",
    "    \"conv_padding\" : 2,\n",
    "    \"conv1_kernel_size\" : 4,\n",
    "    \"conv2_kernel_size\" : 5,\n",
    "    \"maxpool_kernel_size\" : 2,\n",
    "    \"second_dropout\" : 0.3,\n",
    "    \"rnn_input_size\": None,\n",
    "    \"rnn_hidden_size\" : 100,\n",
    "    \"rnn_num_layers\" : 1,\n",
    "    \"first_dense_in\":None,\n",
    "    \"first_dense_out\" : 400,\n",
    "    \"third_dropout\" : 0.15,\n",
    "    \"second_dense_in\" : None,\n",
    "    \"second_dense_out\" : None\n",
    "    }\n",
    "\n",
    "ReviewModelParam[\"conv_input_channel\"] = ReviewModelParam[\"embedding_dim\"]\n",
    "ReviewModelParam[\"rnn_input_size\"] = ReviewModelParam[\"conv_output_channel\"]*2\n",
    "ReviewModelParam[\"first_dense_in\"] = ReviewModelParam[\"max_length\"]//2 * ReviewModelParam[\"rnn_hidden_size\"]\n",
    "ReviewModelParam[\"second_dense_in\"] = ReviewModelParam[\"first_dense_out\"]\n",
    "ReviewModelParam[\"second_dense_out\"] = ReviewModelParam[\"output_dim\"]  ##depends on loss function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch import NeuralNetClassifier\n",
    "import torch.optim as optim\n",
    "from skorch.callbacks import EpochScoring,LRScheduler, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    ('es1',EpochScoring('accuracy')),\n",
    "    ('lrs',LRScheduler()),\n",
    "    ('est',EarlyStopping()),\n",
    "    \n",
    "]\n",
    "batch_size = 128\n",
    "device = torch.device(\"cuda\")\n",
    "model = ReviewModel(ReviewModelParam).to(device)\n",
    "#model = DynamicModel(batch_size,parameter_dict=SST1_DATASET_PARAMETERS).to(device)\n",
    "net = NeuralNetClassifier(model,## change dimensionality\n",
    "                          iterator_train__drop_last = True,\n",
    "                          iterator_valid__drop_last = True, \n",
    "                          iterator_train__shuffle = True,\n",
    "                          iterator_valid__shuffle = True,\n",
    "                          max_epochs=100, \n",
    "                          criterion = nn.CrossEntropyLoss, \n",
    "                          #criterion__weight = weight, \n",
    "                          optimizer=optim.Adam,\n",
    "                          lr = 0.01,\n",
    "                          # optimizer__param_groups = {('momentum', 0.3)},\n",
    "                          batch_size = batch_size,\n",
    "                          callbacks = callbacks,\n",
    "                          device = device,verbose = 1\n",
    "                          )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    accuracy    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ----------  ------------  -----------  ------------  -------\n",
      "      1      \u001b[36m0.5617\u001b[0m        \u001b[32m4.3914\u001b[0m       \u001b[35m0.5617\u001b[0m        \u001b[31m1.2019\u001b[0m  31.8914\n",
      "      2      \u001b[36m0.5615\u001b[0m        \u001b[32m1.2021\u001b[0m       0.5615        1.2045  31.7745\n",
      "      3      0.5620        1.2027       \u001b[35m0.5620\u001b[0m        1.2032  31.7833\n",
      "      4      \u001b[36m0.5613\u001b[0m        1.2031       0.5613        1.2021  32.0704\n",
      "      5      0.5618        1.2028       0.5618        \u001b[31m1.2017\u001b[0m  33.7759\n",
      "      6      0.5625        1.2027       \u001b[35m0.5625\u001b[0m        \u001b[31m1.2012\u001b[0m  31.9389\n",
      "      7      0.5618        1.2024       0.5618        1.2021  31.8940\n",
      "      8      0.5625        1.2031       0.5625        \u001b[31m1.2008\u001b[0m  31.8915\n",
      "      9      0.5623        1.2021       0.5623        1.2018  31.8913\n",
      "     10      \u001b[36m0.5606\u001b[0m        \u001b[32m1.2020\u001b[0m       0.5606        1.2034  31.8930\n",
      "     11      0.5623        1.2020       0.5623        1.2014  31.9004\n",
      "     12      0.5617        1.2031       0.5617        1.2048  31.9013\n",
      "     13      0.5635        1.2034       \u001b[35m0.5635\u001b[0m        \u001b[31m1.2000\u001b[0m  31.9070\n",
      "     14      0.5615        1.2032       0.5615        1.2053  31.9029\n",
      "     15      0.5608        1.6692       0.5608        1.2053  32.4967\n",
      "     16      0.5608        1.2030       0.5608        1.2046  31.9097\n",
      "     17      0.5610        1.2032       0.5610        1.2042  31.9254\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=ReviewModel(\n",
       "    (embedding): Embedding(52656, 50)\n",
       "    (drop1): Dropout(p=0.5)\n",
       "    (conv1): Conv1d(50, 200, kernel_size=(4,), stride=(1,), padding=(2,))\n",
       "    (conv2): Conv1d(50, 200, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "    (maxpool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (drop2): Dropout(p=0.3)\n",
       "    (rnn): GRU(400, 100)\n",
       "    (flatten): Flatten()\n",
       "    (fc1): Linear(in_features=3000, out_features=400, bias=True)\n",
       "    (drop3): Dropout(p=0.15)\n",
       "    (fc2): Linear(in_features=400, out_features=5, bias=True)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.from_numpy(data_loader.X_train).long().to(device)\n",
    "labels = torch.tensor(data_loader.y_train.values).long().to(device)\n",
    "net.fit(inputs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([29700, 60])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.from_numpy(data_loader.X_train).long().to(device)\n",
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Dropout(p=0.5)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace)\n",
      "    (5): Dropout(p=0.5)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import 29700, 60\n",
    "modela = models.vgg16()\n",
    "print(modela)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "summary(model,torch.LongTensor(inputs.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "with open(\"model.pkl\", 'wb') as f:\n",
    "    pickle.dump(\"model\",f)\n",
    "   \n",
    "# load model\n",
    "with open(\"model.pkl\",\"rb\") as f: \n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#todo plot losses\n",
    "#todo plot accuracy\n",
    "#todo confusion matrix\n",
    "history = net.history\n",
    "train_losses = history[:, 'train_loss']\n",
    "valid_losses = history[:, 'valid_loss']\n",
    "\n",
    "accuracy = history[:, 'accuracy']\n",
    "plot_losses(train_losses, valid_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SST2_DATASET_PARAMETERS = {\n",
    "    \"cell_one_parameter_dict\" : {\n",
    "        \"sent_length\": 19,\n",
    "        \"conv_kernel_size\": (7, 1),\n",
    "        \"conv_input_channels\": 1,\n",
    "        \"conv_output_channels\": 6,\n",
    "        \"conv_stride\": (1, 1),\n",
    "        \"k_max_number\": 10,\n",
    "        \"folding_kernel_size\": (1, 2),\n",
    "        \"folding_stride\": (1, 2)\n",
    "    },\n",
    "    \"cell_two_parameter_dict\" : {\n",
    "        \"sent_length\": None,\n",
    "        \"conv_kernel_size\": (5, 1),\n",
    "        \"conv_input_channels\": 6,\n",
    "        \"conv_output_channels\": 14,\n",
    "        \"conv_stride\": (1, 1),\n",
    "        \"k_max_number\": 4,\n",
    "        \"folding_kernel_size\": (1, 2),\n",
    "        \"folding_stride\": (1, 2)\n",
    "    },\n",
    "    \"dropout_rate\": 0.5,\n",
    "    \"embedding_dim\": 50,\n",
    "    \"vocab_length\": data_loader.weight_matrix,\n",
    "    \"output_dim\": 2\n",
    "}\n",
    "SST2_DATASET_PARAMETERS[\"cell_two_parameter_dict\"][\"sent_length\"] = SST2_DATASET_PARAMETERS[\"cell_one_parameter_dict\"][\"k_max_number\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43053086419753084"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(data_loader.X_train)/(data_loader.X_train.shape[0]*data_loader.X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52656, 50)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader.weight_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29700, 60)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader.X_train.shape\n",
    "# data_loader.buildCorpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.086776733398438\n"
     ]
    }
   ],
   "source": [
    "weight_matrix = data_loader.weight_matrix\n",
    "import sys\n",
    "print(sys.getsizeof(weight_matrix)/(2**20))\n",
    "\n",
    "# print(weight_matrix[0])\n",
    "# print(weight_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(weight_matrix,  open('./data/GloveMatrix.npy', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "c = Counter(data_loader.y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3.0, 22.757575757575758),\n",
       " (4.0, 56.18518518518518),\n",
       " (0.0, 4.562289562289562),\n",
       " (2.0, 11.26936026936027),\n",
       " (1.0, 5.225589225589226)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(i, c[i]/len(data_loader.y_train)*100) for i in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = Variable(torch.cuda.FloatTensor([0.4,0.5,0.11,0.23,0.56])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch.callbacks import EpochScoring,LRScheduler, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#     'lr': [0.001, 0.005, 0.01, 0.05, 0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "#     'max_epochs': list(range(10,100,20))\n",
    "# }\n",
    "# gs = GridSearchCV(net, params, refit = False, scoring = 'accuracy',verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-1ce37bf648a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "inputs = torch.from_numpy(data_loader.X_train).long().to(device)\n",
    "labels = torch.tensor(data_loader.y_train.values).long().to(device)\n",
    "net.fit(inputs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "with open(\"model.pkl\", 'wb') as f:\n",
    "    pickle.dump(\"model\",f)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"model.pkl\",\"rb\") as f: \n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_losses(tr_loss, val_loss):\n",
    "    plt.plot(tr_loss, label=\"training\")\n",
    "    plt.plot(val_loss, label=\"validation\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo plot losses\n",
    "#todo plot accuracy\n",
    "#todo confusion matrix\n",
    "history = net.history\n",
    "train_losses = history[:, 'train_loss']\n",
    "valid_losses = history[:, 'valid_loss']\n",
    "\n",
    "accuracy = history[:, 'accuracy']\n",
    "plot_losses(train_losses, valid_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "SST1_DATASET_PARAMETERS = {\n",
    "    \"cell_one_parameter_dict\" : {\n",
    "        \"sent_length\": 60,\n",
    "        \"conv_kernel_size\": (10, 1),\n",
    "        \"conv_input_channels\": 1,\n",
    "        \"conv_output_channels\": 6,\n",
    "        \"conv_stride\": (1, 1),\n",
    "        \"k_max_number\": 9,\n",
    "        \"folding_kernel_size\": (1, 2),\n",
    "        \"folding_stride\": (1, 2)\n",
    "    },\n",
    "    \"cell_two_parameter_dict\" : \n",
    "        \"sent_length\": None,\n",
    "        \"conv_kernel_size\": (7, 1),\n",
    "        \"conv_input_channels\": 6,\n",
    "        \"conv_output_channels\": 12,\n",
    "        \"conv_stride\": (1, 1),\n",
    "        \"k_max_number\": 5,\n",
    "        \"folding_kernel_size\": (1, 2),\n",
    "        \"folding_stride\": (1, 2)\n",
    "    },\n",
    "    \"dropout_rate\": 0.5,\n",
    "    \"embedding_dim\": 50,\n",
    "    \"vocab_length\": data_loader.weight_matrix.shape[0],\n",
    "    \"output_dim\": 5\n",
    "}\n",
    "SST1_DATASET_PARAMETERS[\"cell_two_parameter_dict\"][\"sent_length\"] = SST1_DATASET_PARAMETERS[\"cell_one_parameter_dict\"][\"k_max_number\"]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
